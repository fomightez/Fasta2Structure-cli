#!/bin/bash




# Get the CURRENT provided results from the official repo.
# Getting those current results so can compare with that I got 
# when I forked, to see if it has been updated in any way since I argue in an issue filed
# at https://github.com/AdamBessa/Fasta2Structure/issues/4
# that `Example_data/Results/Structure.str` doesn't actually match real results.
cd tests
mkdir current_results_provided_by_Adam_Bessa && cd current_results_provided_by_Adam_Bessa
curl -OL https://raw.githubusercontent.com/AdamBessa/Fasta2Structure/main/Example_data/Results/Structure.str
cd ~

# Make a version of provided results that actuall matches expected results.
# Currently, in the issue https://github.com/AdamBessa/Fasta2Structure/issues/4 I point out
# `Fasta2Structure.py` doesn't make a file with the header and the first row after the identifier
# shown there. So I'd prefer to have the provided example match what it should for more 
# accurate testing. This awk command will save a version of the that should match better to 
# what current script ACTUALLY gives. (Specifically, it removes the first row, which are 
# column names that I don't know the source of and it also removes the fist column after the
# identifier, which I also don' know the source of. Plus, I think Adam BEssa's had tabs and 
# I am not getting results out that have tabs. So fixes.) The result of that I can then use to 
# compare to what improved script gives so that I can easily check going forward that 
# changes to the script don't change the results.
: <<'END_COMMENT' # This COMMENTED OUT section was way that worked but convoluted, BUT INCLUDES MANY USEFUL TRICKS, because done piecemeal and replaced with streamlined now after this 'here-document that is used as a multi-line comment' according to https://stackoverflow.com/a/46049228/8508004
awk 'NR>1 {
    printf "%s", $1;
    for (i=3; i<=NF; i++) {
        if ($i ~ /^-/) {
            printf " %s", $i;
        } else {
            printf "  %s", $i;
        }
    }
    #printf "\n";
}' Example_data/Results/Structure.str > Example_data/Results/temp_output.str
# Step 2: add standard lne endings to normalize (weird line endings diagnosed with `cat -A Example_data/Results/temp_output.str | tail -n 5` & `file Example_data/Results/temp_output.str`)
tr '\r' '\n' < Example_data/Results/temp_output.str > Example_data/Results/temp_unix.str
# Step 3:  add a space at the end of each line without adding a new line
awk '{print $0 " "}' Example_data/Results/temp_unix.str > Example_data/Results/EXPECTED_in_July2024_Structure.str
# Step 4:
# Remove the temporary files
rm Example_data/Results/temp_output.str
rm Example_data/Results/temp_unix.str
END_COMMENT

awk 'NR>1 {
    printf "%s", $1;
    for (i=3; i<=NF; i++) {
        if ($i ~ /^-/) {
            printf " %s", $i;
        } else {
            printf "  %s", $i;
        }
    }
    printf " \n";
}' Example_data/Results/Structure.str | tr -d '\r' > Example_data/Results/EXPECTED_in_July2024_Structure.str


# OLD BUT KEEPING BECAUSE USEFUL CODE WAS WORKING OUT AND NICE SPLITING A FILE WITH BASH ON A SYMBOL!!
# I realized the dataset data, even though being from different genes, is meant to be 
# selected all at same time in demo and so I don't need to make related files to demo
# those separate, but this could be useful code and SO JUST COMMENTING OUT FOR NOW

#***----------------------------------------------------------------------------------***#
# MAKE FOUR RELATED FASTA FILES
#***----------------------------------------------------------------------------------***#
# Make a directory for multiple related FASTA files to be stored under 'Example_data'
#mkdir ./Example_data/Datasets/related_individual_files

# Split up multisequence example in `Example_data/Datasets` to make multiple related FASTA files in 
# the new directory `related_individual_files`, based on https://www.biostars.org/p/9461227/#9461227 (I planned to use Jim Kent's `faSplit` but when I ran `./faSplit sequence Example_data/Datasets/ITS.fas 588 ITS_ind` it only produced 565 files when there should be 588 -- explanation when I looked was example where it kept `AgMRJ30_1` and `AgMRJ30_2` together and so it seems it is too smart and keeping related files together. [I suspect it may be related to 'regions' concept because when I looked at using `faidx` that comes intalled when you get the `pyfaidx` package it had for the `--split-files` flag "write each region to a separate file (names are derived from regions)".] THAT AND `FAIDX` COULD BE POTENTIALLY USEFUL. But here I was looking for a dumber approach that just split them.)
# the awk command offered there didn't deal with with carriage returns I was seeing at end of the description line and so this one filters them out
#mkdir -p split_sequences
#count=0
#filename=""
#while IFS= read -r line; do
#    if [[ $line == ">"* ]]; then
#        # Extract the sequence ID
#        id=$(echo "$line" | sed 's/^>//;s/[^a-zA-Z0-9_].*$//')
#        if [[ -n "$id" ]]; then
#            filename="split_sequences/${id}.fa"
#            echo "Creating file: $filename"
#            echo "$line" > "$filename"
#            ((count++))
#        else
#            echo "WARNING: Found header line with no valid identifier: $line"
#            filename=""
#        fi
#    elif [[ -n "$filename" ]]; then
#        echo "$line" >> "$filename"
#    else
#        echo "WARNING: Found sequence data outside of a valid sequence: $line"
#    fi
#done < <(sed 's/\r//g' Example_data/Datasets/ITS.fas)

# Move four of those to `Example_data/Datasets/related_individual_files`
#mv split_sequences/AgALC20_1.fa split_sequences/AgMRJ27_1.fa split_sequences/AgPAa21_1.fa split_sequences/AgPNB19_1.fa Example_data/Datasets/related_individual_files/

# remove the `split_sequences` directory I used to unpack all in ITS.fas
#rm -rf split_sequences
#***---------------End of MAKE FOUR RELATED FASTA FILES------------------------------***#
